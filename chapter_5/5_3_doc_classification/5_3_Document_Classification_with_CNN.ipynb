{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7WMNRY8Xybh"
   },
   "source": [
    "*아래 링크를 통해 이 노트북을 주피터 노트북 뷰어(nbviewer.jupyter.org)로 보거나 구글 코랩(colab.research.google.com)에서 실행할 수 있습니다.*\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/rickiepark/nlp-with-pytorch/blob/master/chapter_5/5_3_doc_classification/5_3_Document_Classification_with_CNN.ipynb\"><img src=\"https://jupyter.org/assets/main-logo.svg\" width=\"28\" />주피터 노트북 뷰어로 보기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/nlp-with-pytorch/blob/master/chapter_5/5_3_doc_classification/5_3_Document_Classification_with_CNN.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyAPP9uUXybr"
   },
   "source": [
    "# 문서 분류를 위해 임베딩 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdVVLCgGXybr"
   },
   "source": [
    "## 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hMcRRAEmXybr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ydf5c9WnXybs"
   },
   "source": [
    "## 데이터 벡터 변환 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsMm_PATXybs"
   },
   "source": [
    "### `Vocabulary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pd6hspAhXybs"
   },
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"매핑을 위해 텍스트를 처리하고 어휘 사전을 만드는 클래스 \"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            token_to_idx (dict): 기존 토큰-인덱스 매핑 딕셔너리\n",
    "        \"\"\"\n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "    def to_serializable(self):\n",
    "        \"\"\" 직렬화할 수 있는 딕셔너리를 반환합니다 \"\"\"\n",
    "        return {'token_to_idx': self._token_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\" 직렬화된 딕셔너리에서 Vocabulary 객체를 만듭니다 \"\"\"\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\" 토큰을 기반으로 매핑 딕셔너리를 업데이트합니다\n",
    "\n",
    "        매개변수:\n",
    "            token (str): Vocabulary에 추가할 토큰\n",
    "        반환값:\n",
    "            index (int): 토큰에 상응하는 정수\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def add_many(self, tokens):\n",
    "        \"\"\"토큰 리스트를 Vocabulary에 추가합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            tokens (list): 문자열 토큰 리스트\n",
    "        반환값:\n",
    "            indices (list): 토큰 리스트에 상응되는 인덱스 리스트\n",
    "        \"\"\"\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"토큰에 대응하는 인덱스를 추출합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            token (str): 찾을 토큰 \n",
    "        반환값:\n",
    "            index (int): 토큰에 해당하는 인덱스\n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\" 인덱스에 해당하는 토큰을 반환합니다.\n",
    "        \n",
    "        매개변수: \n",
    "            index (int): 찾을 인덱스\n",
    "        반환값:\n",
    "            token (str): 인텍스에 해당하는 토큰\n",
    "        에러:\n",
    "            KeyError: 인덱스가 Vocabulary에 없을 때 발생합니다.\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VoeSTQK_Xybt"
   },
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        contents = super(SequenceVocabulary, self).to_serializable()\n",
    "        contents.update({'unk_token': self._unk_token,\n",
    "                         'mask_token': self._mask_token,\n",
    "                         'begin_seq_token': self._begin_seq_token,\n",
    "                         'end_seq_token': self._end_seq_token})\n",
    "        return contents\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\" 토큰에 대응하는 인덱스를 추출합니다.\n",
    "        토큰이 없으면 UNK 인덱스를 반환합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            token (str): 찾을 토큰 \n",
    "        반환값:\n",
    "            index (int): 토큰에 해당하는 인덱스\n",
    "        노트:\n",
    "            UNK 토큰을 사용하려면 (Vocabulary에 추가하기 위해)\n",
    "            `unk_index`가 0보다 커야 합니다.\n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooOjYu7fXybt"
   },
   "source": [
    "### `Vectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EA-koGnRXybt"
   },
   "outputs": [],
   "source": [
    "class NewsVectorizer(object):\n",
    "    \"\"\" 어휘 사전을 생성하고 관리합니다 \"\"\"\n",
    "    def __init__(self, title_vocab, category_vocab):\n",
    "        self.title_vocab = title_vocab\n",
    "        self.category_vocab = category_vocab\n",
    "\n",
    "    def vectorize(self, title, vector_length=-1):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            title (str): 공백으로 나누어진 단어 문자열\n",
    "            vector_length (int): 인덱스 벡터의 길이 매개변수\n",
    "        반환값:\n",
    "            벡터로 변환된 제목 (numpy.array)\n",
    "        \"\"\"\n",
    "        indices = [self.title_vocab.begin_seq_index]\n",
    "        indices.extend(self.title_vocab.lookup_token(token) \n",
    "                       for token in title.split(\" \"))\n",
    "        indices.append(self.title_vocab.end_seq_index)\n",
    "\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        out_vector[:len(indices)] = indices\n",
    "        out_vector[len(indices):] = self.title_vocab.mask_index\n",
    "\n",
    "        return out_vector\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, news_df, cutoff=25):\n",
    "        \"\"\"데이터셋 데이터프레임에서 Vectorizer 객체를 만듭니다\n",
    "        \n",
    "        매개변수:\n",
    "            news_df (pandas.DataFrame): 타깃 데이터셋\n",
    "            cutoff (int): Vocabulary에 포함할 빈도 임곗값\n",
    "        반환값:\n",
    "            NewsVectorizer 객체\n",
    "        \"\"\"\n",
    "        category_vocab = Vocabulary()        \n",
    "        for category in sorted(set(news_df.category)):\n",
    "            category_vocab.add_token(category)\n",
    "\n",
    "        word_counts = Counter()\n",
    "        for title in news_df.title:\n",
    "            for token in title.split(\" \"):\n",
    "                if token not in string.punctuation:\n",
    "                    word_counts[token] += 1\n",
    "        \n",
    "        title_vocab = SequenceVocabulary()\n",
    "        for word, word_count in word_counts.items():\n",
    "            if word_count >= cutoff:\n",
    "                title_vocab.add_token(word)\n",
    "        \n",
    "        return cls(title_vocab, category_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        title_vocab = \\\n",
    "            SequenceVocabulary.from_serializable(contents['title_vocab'])\n",
    "        category_vocab =  \\\n",
    "            Vocabulary.from_serializable(contents['category_vocab'])\n",
    "\n",
    "        return cls(title_vocab=title_vocab, category_vocab=category_vocab)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {'title_vocab': self.title_vocab.to_serializable(),\n",
    "                'category_vocab': self.category_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8KDtWp0Xybt"
   },
   "source": [
    "### `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vv0vtznzXybu"
   },
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, news_df, vectorizer):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            news_df (pandas.DataFrame): 데이터셋\n",
    "            vectorizer (NewsVectorizer): 데이터셋에서 만든 NewsVectorizer 객체\n",
    "        \"\"\"\n",
    "        self.news_df = news_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        # +1 if only using begin_seq, +2 if using both begin and end seq tokens\n",
    "        measure_len = lambda context: len(context.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, news_df.title)) + 2\n",
    "        \n",
    "\n",
    "        self.train_df = self.news_df[self.news_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.news_df[self.news_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.news_df[self.news_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "\n",
    "        # 클래스 가중치\n",
    "        class_counts = news_df.category.value_counts().to_dict()\n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.category_vocab.lookup_token(item[0])\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, news_csv):\n",
    "        \"\"\"데이터셋을 로드하고 처음부터 새로운 Vectorizer 만들기\n",
    "        \n",
    "        매개변수:\n",
    "            news_csv (str): 데이터셋의 위치\n",
    "        반환값:\n",
    "            NewsDataset의 인스턴스\n",
    "        \"\"\"\n",
    "        news_df = pd.read_csv(news_csv)\n",
    "        train_news_df = news_df[news_df.split=='train']\n",
    "        return cls(news_df, NewsVectorizer.from_dataframe(train_news_df))\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, news_csv, vectorizer_filepath):\n",
    "        \"\"\" 데이터셋을 로드하고 새로운 Vectorizer 객체를 만듭니다.\n",
    "        캐시된 Vectorizer 객체를 재사용할 때 사용합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            news_csv (str): 데이터셋의 위치\n",
    "            vectorizer_filepath (str): NewsDataset 객체의 저장 위치\n",
    "        반환값:\n",
    "            NewsDataset의 인스턴스\n",
    "        \"\"\"\n",
    "        news_df = pd.read_csv(news_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(news_csv, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        \"\"\"파일에서 Vectorizer 객체를 로드하는 정적 메서드\n",
    "        \n",
    "        매개변수:\n",
    "            vectorizer_filepath (str): 직렬화된 Vectorizer 객체의 위치\n",
    "        반환값:\n",
    "            NewsVectorizer의 인스턴스\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return NameVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        \"\"\"NewsVectorizer 객체를 json 형태로 디스크에 저장합니다\n",
    "        \n",
    "        매개변수:\n",
    "            vectorizer_filepath (str): NewsVectorizer 객체의 저장 위치\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" 벡터 변환 객체를 반환합니다 \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" 데이터프레임에 있는 열을 사용해 분할 세트를 선택합니다 \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"파이토치 데이터셋의 주요 진입 메서드\n",
    "        \n",
    "        매개변수:\n",
    "            index (int): 데이터 포인트의 인덱스\n",
    "        반환값:\n",
    "            데이터 포인트의 특성(x_data)과 레이블(y_target)로 이루어진 딕셔너리\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        title_vector = \\\n",
    "            self._vectorizer.vectorize(row.title, self._max_seq_length)\n",
    "\n",
    "        category_index = \\\n",
    "            self._vectorizer.category_vocab.lookup_token(row.category)\n",
    "\n",
    "        return {'x_data': title_vector,\n",
    "                'y_target': category_index}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"배치 크기가 주어지면 데이터셋으로 만들 수 있는 배치 개수를 반환합니다\n",
    "        \n",
    "        매개변수:\n",
    "            batch_size (int)\n",
    "        반환값:\n",
    "            배치 개수\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    파이토치 DataLoader를 감싸고 있는 제너레이터 함수.\n",
    "    걱 텐서를 지정된 장치로 이동합니다.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex3ye3RsXybu"
   },
   "source": [
    "## 모델: `NewsClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mO99LbRqXybu"
   },
   "outputs": [],
   "source": [
    "class NewsClassifier(nn.Module):\n",
    "    def __init__(self, embedding_size, num_embeddings, num_channels, \n",
    "                 hidden_dim, num_classes, dropout_p, \n",
    "                 pretrained_embeddings=None, padding_idx=0):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            embedding_size (int): 임베딩 벡터의 크기\n",
    "            num_embeddings (int): 임베딩 벡터의 개수\n",
    "            num_channels (int): 합성곱 커널 개수\n",
    "            hidden_dim (int): 은닉 차원 크기\n",
    "            num_classes (int): 클래스 개수\n",
    "            dropout_p (float): 드롭아웃 확률\n",
    "            pretrained_embeddings (numpy.array): 사전에 훈련된 단어 임베딩\n",
    "                기본값은 None \n",
    "            padding_idx (int): 패딩 인덱스\n",
    "        \"\"\"\n",
    "        super(NewsClassifier, self).__init__()\n",
    "\n",
    "        if pretrained_embeddings is None:\n",
    "\n",
    "            self.emb = nn.Embedding(embedding_dim=embedding_size,\n",
    "                                    num_embeddings=num_embeddings,\n",
    "                                    padding_idx=padding_idx)        \n",
    "        else:\n",
    "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
    "            self.emb = nn.Embedding(embedding_dim=embedding_size,\n",
    "                                    num_embeddings=num_embeddings,\n",
    "                                    padding_idx=padding_idx,\n",
    "                                    _weight=pretrained_embeddings)\n",
    "        \n",
    "            \n",
    "        self.convnet = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=embedding_size, \n",
    "                   out_channels=num_channels, kernel_size=3),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n",
    "                   kernel_size=3, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n",
    "                   kernel_size=3, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n",
    "                   kernel_size=3),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "        self._dropout_p = dropout_p\n",
    "        self.fc1 = nn.Linear(num_channels, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"분류기의 정방향 계산\n",
    "        \n",
    "        매개변수:\n",
    "            x_in (torch.Tensor): 입력 데이터 텐서 \n",
    "                x_in.shape는 (batch, dataset._max_seq_length)입니다.\n",
    "            apply_softmax (bool): 소프트맥스 활성화 함수를 위한 플래그\n",
    "                크로스-엔트로피 손실을 사용하려면 False로 지정합니다\n",
    "        반환값:\n",
    "            결과 텐서. tensor.shape은 (batch, num_classes)입니다.\n",
    "        \"\"\"\n",
    "        \n",
    "        # 임베딩을 적용하고 특성과 채널 차원을 바꿉니다\n",
    "        x_embedded = self.emb(x_in).permute(0, 2, 1)\n",
    "\n",
    "        features = self.convnet(x_embedded)\n",
    "\n",
    "        # 평균 값을 계산하여 부가적인 차원을 제거합니다\n",
    "        remaining_size = features.size(dim=2)\n",
    "        features = F.avg_pool1d(features, remaining_size).squeeze(dim=2)\n",
    "        features = F.dropout(features, p=self._dropout_p)\n",
    "        \n",
    "        # MLP 분류기\n",
    "        intermediate_vector = F.relu(F.dropout(self.fc1(features), p=self._dropout_p))\n",
    "        prediction_vector = self.fc2(intermediate_vector)\n",
    "\n",
    "        if apply_softmax:\n",
    "            prediction_vector = F.softmax(prediction_vector, dim=1)\n",
    "\n",
    "        return prediction_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEMNjR-uXybu"
   },
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZSWkMlvXybv"
   },
   "source": [
    "### 헬퍼 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JHW0JTZpXybv"
   },
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"훈련 상태를 업데이트합니다.\n",
    "\n",
    "    Components:\n",
    "     - 조기 종료: 과대 적합 방지\n",
    "     - 모델 체크포인트: 더 나은 모델을 저장합니다\n",
    "\n",
    "    :param args: 메인 매개변수\n",
    "    :param model: 훈련할 모델\n",
    "    :param train_state: 훈련 상태를 담은 딕셔너리\n",
    "    :returns:\n",
    "        새로운 훈련 상태\n",
    "    \"\"\"\n",
    "\n",
    "    # 적어도 한 번 모델을 저장합니다\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # 성능이 향상되면 모델을 저장합니다\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # 손실이 나빠지면\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # 조기 종료 단계 업데이트\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # 손실이 감소하면\n",
    "        else:\n",
    "            # 최상의 모델 저장\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "\n",
    "            # 조기 종료 단계 재설정\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # 조기 종료 여부 확인\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5s2Ba-C9Xybv"
   },
   "source": [
    "#### 일반 유틸리티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xhdayyT6Xybw"
   },
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "        \n",
    "def load_glove_from_file(glove_filepath):\n",
    "    \"\"\"GloVe 임베딩 로드 \n",
    "    \n",
    "    매개변수:\n",
    "        glove_filepath (str): 임베딩 파일 경로 \n",
    "    반환값:\n",
    "        word_to_index (dict), embeddings (numpy.ndarary)\n",
    "    \"\"\"\n",
    "\n",
    "    word_to_index = {}\n",
    "    embeddings = []\n",
    "    with open(glove_filepath, \"r\") as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            line = line.split(\" \") # each line: word num1 num2 ...\n",
    "            word_to_index[line[0]] = index # word = line[0] \n",
    "            embedding_i = np.array([float(val) for val in line[1:]])\n",
    "            embeddings.append(embedding_i)\n",
    "    return word_to_index, np.stack(embeddings)\n",
    "\n",
    "def make_embedding_matrix(glove_filepath, words):\n",
    "    \"\"\"\n",
    "    특정 단어 집합에 대한 임베딩 행렬을 만듭니다.\n",
    "    \n",
    "    매개변수:\n",
    "        glove_filepath (str): 임베딩 파일 경로\n",
    "        words (list): 단어 리스트\n",
    "    \"\"\"\n",
    "    word_to_idx, glove_embeddings = load_glove_from_file(glove_filepath)\n",
    "    embedding_size = glove_embeddings.shape[1]\n",
    "    \n",
    "    final_embeddings = np.zeros((len(words), embedding_size))\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word in word_to_idx:\n",
    "            final_embeddings[i, :] = glove_embeddings[word_to_idx[word]]\n",
    "        else:\n",
    "            embedding_i = torch.ones(1, embedding_size)\n",
    "            torch.nn.init.xavier_uniform_(embedding_i)\n",
    "            final_embeddings[i, :] = embedding_i\n",
    "\n",
    "    return final_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHxGgBeqXybw"
   },
   "source": [
    "### 설정과 전처리 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "I7i_gcdLXybw"
   },
   "outputs": [],
   "source": [
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qp1KmNlNXybw",
    "outputId": "d2d1ed80-32da-4277-a589-32991be7ea7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 경로: \n",
      "\tmodel_storage/ch5/document_classification/vectorizer.json\n",
      "\tmodel_storage/ch5/document_classification/model.pth\n",
      "CUDA 사용여부: True\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # 날짜와 경로 정보\n",
    "    news_csv=\"data/ag_news/news_with_splits.csv\",\n",
    "    vectorizer_file=\"vectorizer.json\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage/ch5/document_classification\",\n",
    "    # 모델 하이퍼파라미터\n",
    "    glove_filepath='data/glove/glove.6B.100d.txt', \n",
    "    use_glove=False,\n",
    "    embedding_size=100, \n",
    "    hidden_dim=100, \n",
    "    num_channels=100, \n",
    "    # 훈련 하이퍼파라미터\n",
    "    seed=1337, \n",
    "    learning_rate=0.001, \n",
    "    dropout_p=0.1, \n",
    "    batch_size=128, \n",
    "    num_epochs=100, \n",
    "    early_stopping_criteria=5, \n",
    "    # 실행 옵션\n",
    "    cuda=True, \n",
    "    catch_keyboard_interrupt=True, \n",
    "    reload_from_files=False,\n",
    "    expand_filepaths_to_save_dir=True\n",
    ") \n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "    print(\"파일 경로: \")\n",
    "    print(\"\\t{}\".format(args.vectorizer_file))\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# CUDA 체크\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "    \n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "print(\"CUDA 사용여부: {}\".format(args.cuda))\n",
    "\n",
    "# 재현성을 위해 시드 설정\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# 디렉토리 처리\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNvsKR3TXybx"
   },
   "source": [
    "### 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Io35JIMXXybx",
    "outputId": "7581b6fa-8780-41ed-b64b-32226a11188a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-17 05:04:06--  https://git.io/Jt1NH\n",
      "Resolving git.io (git.io)... 3.223.68.239, 54.235.211.105, 34.193.233.154, ...\n",
      "Connecting to git.io (git.io)|3.223.68.239|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_5/5_3_doc_classification/data/download.py [following]\n",
      "--2021-02-17 05:04:06--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_5/5_3_doc_classification/data/download.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1572 (1.5K) [text/plain]\n",
      "Saving to: ‘data/download.py’\n",
      "\n",
      "data/download.py    100%[===================>]   1.54K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-02-17 05:04:06 (27.4 MB/s) - ‘data/download.py’ saved [1572/1572]\n",
      "\n",
      "--2021-02-17 05:04:06--  https://git.io/Jt1NS\n",
      "Resolving git.io (git.io)... 3.223.68.239, 54.235.211.105, 34.193.233.154, ...\n",
      "Connecting to git.io (git.io)|3.223.68.239|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_5/5_3_doc_classification/data/get-all-data.sh [following]\n",
      "--2021-02-17 05:04:06--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_5/5_3_doc_classification/data/get-all-data.sh\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 489 [text/plain]\n",
      "Saving to: ‘data/get-all-data.sh’\n",
      "\n",
      "data/get-all-data.s 100%[===================>]     489  --.-KB/s    in 0s      \n",
      "\n",
      "2021-02-17 05:04:06 (29.2 MB/s) - ‘data/get-all-data.sh’ saved [489/489]\n",
      "\n",
      "/content/data\n",
      "Trying to fetch /content/data/ag_news/news.csv\n",
      "188it [00:00, 2619.69it/s]\n",
      "Trying to fetch /content/data/ag_news/news_with_splits.csv\n",
      "208it [00:00, 2156.21it/s]\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "# 만약 코랩에서 실행하는 경우 아래 코드를 실행하여 전처리된 라이트 버전의 데이터를 다운로드하세요.\n",
    "!mkdir data\n",
    "!wget https://git.io/Jt1NH -O data/download.py\n",
    "!wget https://git.io/Jt1NS -O data/get-all-data.sh\n",
    "!chmod 755 data/get-all-data.sh\n",
    "%cd data\n",
    "!./get-all-data.sh\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJ9Y89qTY8_0",
    "outputId": "541db62d-ab50-4bb3-f704-479ec06b8068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-17 05:08:35--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2021-02-17 05:08:35--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-02-17 05:08:35--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  2.14MB/s    in 6m 50s  \n",
      "\n",
      "2021-02-17 05:15:26 (2.00 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n",
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "# GloVe 데이터를 다운로드합니다.\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove.6B.zip\n",
    "!mkdir -p data/glove\n",
    "!mv glove.6B.100d.txt data/glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "98bH62mUXybx"
   },
   "outputs": [],
   "source": [
    "args.use_glove = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHU5W9XrXyby",
    "outputId": "eb254451-c8bc-43f6-f239-287079d6fe73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사전 훈련된 임베딩을 사용합니다\n"
     ]
    }
   ],
   "source": [
    "if args.reload_from_files:\n",
    "    # 체크포인트를 로드합니다.\n",
    "    dataset = NewsDataset.load_dataset_and_load_vectorizer(args.news_csv,\n",
    "                                                              args.vectorizer_file)\n",
    "else:\n",
    "    # 데이터셋과 Vectorizer를 만듭니다.\n",
    "    dataset = NewsDataset.load_dataset_and_make_vectorizer(args.news_csv)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "# GloVe를 사용하거나 랜덤하게 임베딩을 초기화합니다\n",
    "if args.use_glove:\n",
    "    words = vectorizer.title_vocab._token_to_idx.keys()\n",
    "    embeddings = make_embedding_matrix(glove_filepath=args.glove_filepath, \n",
    "                                       words=words)\n",
    "    print(\"사전 훈련된 임베딩을 사용합니다\")\n",
    "else:\n",
    "    print(\"사전 훈련된 임베딩을 사용하지 않습니다\")\n",
    "    embeddings = None\n",
    "\n",
    "classifier = NewsClassifier(embedding_size=args.embedding_size, \n",
    "                            num_embeddings=len(vectorizer.title_vocab),\n",
    "                            num_channels=args.num_channels,\n",
    "                            hidden_dim=args.hidden_dim, \n",
    "                            num_classes=len(vectorizer.category_vocab), \n",
    "                            dropout_p=args.dropout_p,\n",
    "                            pretrained_embeddings=embeddings,\n",
    "                            padding_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4U8V0J5wXyby"
   },
   "source": [
    "### 훈련 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249,
     "referenced_widgets": [
      "e15bcc791cf54c73bdacd7a15d030be4",
      "569eef4f1a054e5a8fe569a5eb684b6a",
      "816137123d6045488e9a8fd526d177be",
      "797685b08d3c4ecd8c30d0c79054b3cd",
      "3462537cd22b43e5a2b737ed16707b9f",
      "4ced23e85c8f4ede87cbcc941ef4f680",
      "2bcabf5862994c1490370b885e0f89d9",
      "775e000644e440d089293e8b910d178a",
      "3598e5e06c0b41c1b7fa667f65eda003",
      "e87214de4511462dbe6bae717bfb1d63",
      "6f7a166b41ab4aa9bc04f9f01668b5d2",
      "8b17c2b18e0b48dc88e3989e93166dea",
      "1137e0b9f0264ce797284b5198a05669",
      "f45329d59e3f4542a6349c61a4f4e988",
      "4929c613bf3e4dfa9a83c0bb2d8033bd",
      "7f68dd4da4ef4123b06719edcb183b06",
      "b581131842734886981ade3f3105731a",
      "e036381fd3f94936b86fd24770e90139",
      "a423d566060044498a756b6ab637a2ff",
      "92f39606bbe3431897eaeb6e4ab75383",
      "488235e00da34f35b6fff060cd969c96",
      "ade7f0af9a6546ad908c50efbc8c154b",
      "b930812f259d44259aed1c658a7c5c46",
      "d2b0a9ccc71541e8995f231e0ee01cc2"
     ]
    },
    "id": "Geai8ybxXyby",
    "outputId": "f13977de-e0bc-4370-f720-46e7c4fec6e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15bcc791cf54c73bdacd7a15d030be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3598e5e06c0b41c1b7fa667f65eda003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=train', max=656.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b581131842734886981ade3f3105731a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=val', max=140.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                           mode='min', factor=0.5,\n",
    "                                           patience=1)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm_notebook(desc='training routine', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm_notebook(desc='split=train',\n",
    "                          total=dataset.get_num_batches(args.batch_size), \n",
    "                          position=1, \n",
    "                          leave=True)\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm_notebook(desc='split=val',\n",
    "                        total=dataset.get_num_batches(args.batch_size), \n",
    "                        position=1, \n",
    "                        leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # 훈련 세트에 대한 순회\n",
    "\n",
    "        # 훈련 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # 훈련 과정은 5단계로 이루어집니다\n",
    "\n",
    "            # --------------------------------------\n",
    "            # 단계 1. 그레이디언트를 0으로 초기화합니다\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 단계 2. 출력을 계산합니다\n",
    "            y_pred = classifier(batch_dict['x_data'])\n",
    "\n",
    "            # 단계 3. 손실을 계산합니다\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # 단계 4. 손실을 사용해 그레이디언트를 계산합니다\n",
    "            loss.backward()\n",
    "\n",
    "            # 단계 5. 옵티마이저로 가중치를 업데이트합니다\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            \n",
    "            # 정확도를 계산합니다\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                                  epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # 검증 세트에 대한 순회\n",
    "\n",
    "        # 검증 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "            # 단계 1. 출력을 계산합니다\n",
    "            y_pred =  classifier(batch_dict['x_data'])\n",
    "\n",
    "            # 단계 2. 손실을 계산합니다\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # 단계 3. 정확도를 계산합니다\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                            epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier,\n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TwvLNmQ8Xybz"
   },
   "outputs": [],
   "source": [
    "# 가장 좋은 모델을 사용해 테스트 세트의 손실과 정확도를 계산합니다\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred =  classifier(batch_dict['x_data'])\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYw9htHUXybz",
    "outputId": "0228464b-b275-438c-b553-dec84d85462e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 손실: 0.6094308755227503;\n",
      "테스트 정확도: 79.79352678571432\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 손실: {};\".format(train_state['test_loss']))\n",
    "print(\"테스트 정확도: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCuOsUatXybz"
   },
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "WFO-CZstXybz"
   },
   "outputs": [],
   "source": [
    "# 리뷰 텍스트를 전처리합니다\n",
    "def preprocess_text(text):\n",
    "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hokPbZ6DXybz"
   },
   "outputs": [],
   "source": [
    "def predict_category(title, classifier, vectorizer, max_length):\n",
    "    \"\"\"뉴스 제목을 기반으로 카테고리를 예측합니다\n",
    "    \n",
    "    매개변수:\n",
    "        title (str): 원시 제목 문자열\n",
    "        classifier (NewsClassifier): 훈련된 분류기 객체\n",
    "        vectorizer (NewsVectorizer): 해당 Vectorizer\n",
    "        max_length (int): 최대 시퀀스 길이\n",
    "            노트: CNN은 입력 텐서 크기에 민감합니다. \n",
    "                 훈련 데이터처럼 동일한 크기를 갖도록 만듭니다.\n",
    "    \"\"\"\n",
    "    title = preprocess_text(title)\n",
    "    vectorized_title = \\\n",
    "        torch.tensor(vectorizer.vectorize(title, vector_length=max_length))\n",
    "    result = classifier(vectorized_title.unsqueeze(0), apply_softmax=True)\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "    predicted_category = vectorizer.category_vocab.lookup_index(indices.item())\n",
    "\n",
    "    return {'category': predicted_category, \n",
    "            'probability': probability_values.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hsrs-T8sXyb0"
   },
   "outputs": [],
   "source": [
    "def get_samples():\n",
    "    samples = {}\n",
    "    for cat in dataset.val_df.category.unique():\n",
    "        samples[cat] = dataset.val_df.title[dataset.val_df.category==cat].tolist()[:5]\n",
    "    return samples\n",
    "\n",
    "val_samples = get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OT46a4SmXyb1",
    "outputId": "c3febde9-e199-45fb-99bf-c34dfd709084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Category: Business\n",
      "==============================\n",
      "예측: Business (p=0.79)\n",
      "\t + 샘플: AZ suspends marketing of cancer drug\n",
      "예측: Business (p=0.98)\n",
      "\t + 샘플: Business world has mixed reaction to Perez move\n",
      "예측: Sports (p=0.75)\n",
      "\t + 샘플: Betting Against Bombay\n",
      "예측: Sci/Tech (p=0.34)\n",
      "\t + 샘플: Malpractice Insurers Face a Tough Market\n",
      "예측: Sports (p=0.76)\n",
      "\t + 샘플: NVIDIA Is Vindicated\n",
      "------------------------------\n",
      "\n",
      "True Category: Sci/Tech\n",
      "==============================\n",
      "예측: World (p=0.75)\n",
      "\t + 샘플: Spies prize webcam #39;s eyes\n",
      "예측: Sci/Tech (p=1.00)\n",
      "\t + 샘플: Sober worm causes headaches\n",
      "예측: World (p=0.76)\n",
      "\t + 샘플: Local Search: Missing Pieces Falling into Place\n",
      "예측: Sci/Tech (p=1.00)\n",
      "\t + 샘플: Hackers baiting Internet users with Beckham pix\n",
      "예측: Sports (p=0.95)\n",
      "\t + 샘플: Nokia adds BlackBerry support to Series 80 handsets\n",
      "------------------------------\n",
      "\n",
      "True Category: Sports\n",
      "==============================\n",
      "예측: Sci/Tech (p=0.49)\n",
      "\t + 샘플: Is Meyer the man to get Irish up?\n",
      "예측: Sci/Tech (p=0.36)\n",
      "\t + 샘플: Who? Who? And Clemens\n",
      "예측: Sports (p=1.00)\n",
      "\t + 샘플: Baseball Today (AP)\n",
      "예측: World (p=0.59)\n",
      "\t + 샘플: Mark Kreidler: Yao Ming epitomizes the Chinese athlete who is &lt;b&gt;...&lt;/b&gt;\n",
      "예측: Sports (p=0.90)\n",
      "\t + 샘플: No. 5 Miami Rebounds to Beat FSU in Overtime\n",
      "------------------------------\n",
      "\n",
      "True Category: World\n",
      "==============================\n",
      "예측: Sports (p=0.79)\n",
      "\t + 샘플: Arafat in pain but expected to recover-Shaath\n",
      "예측: World (p=1.00)\n",
      "\t + 샘플: Maoist rebels bomb Kathmandu building, no injuries (Reuters)\n",
      "예측: World (p=1.00)\n",
      "\t + 샘플: Son Running for Ill. Rep.'s House Seat (AP)\n",
      "예측: World (p=0.61)\n",
      "\t + 샘플: Strong Quake Hits in Japan\n",
      "예측: World (p=1.00)\n",
      "\t + 샘플: Israel assassinates Hamas militant in Damascus\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#title = input(\"Enter a news title to classify: \")\n",
    "classifier = classifier.to(\"cpu\")\n",
    "\n",
    "for truth, sample_group in val_samples.items():\n",
    "    print(f\"True Category: {truth}\")\n",
    "    print(\"=\"*30)\n",
    "    for sample in sample_group:\n",
    "        prediction = predict_category(sample, classifier, \n",
    "                                      vectorizer, dataset._max_seq_length + 1)\n",
    "        print(\"예측: {} (p={:0.2f})\".format(prediction['category'],\n",
    "                                                  prediction['probability']))\n",
    "        print(\"\\t + 샘플: {}\".format(sample))\n",
    "    print(\"-\"*30 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "5_3_Document_Classification_with_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": "5",
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1137e0b9f0264ce797284b5198a05669": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2bcabf5862994c1490370b885e0f89d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3462537cd22b43e5a2b737ed16707b9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3598e5e06c0b41c1b7fa667f65eda003": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f7a166b41ab4aa9bc04f9f01668b5d2",
       "IPY_MODEL_8b17c2b18e0b48dc88e3989e93166dea"
      ],
      "layout": "IPY_MODEL_e87214de4511462dbe6bae717bfb1d63"
     }
    },
    "488235e00da34f35b6fff060cd969c96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4929c613bf3e4dfa9a83c0bb2d8033bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ced23e85c8f4ede87cbcc941ef4f680": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "569eef4f1a054e5a8fe569a5eb684b6a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f7a166b41ab4aa9bc04f9f01668b5d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "split=train: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f45329d59e3f4542a6349c61a4f4e988",
      "max": 656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1137e0b9f0264ce797284b5198a05669",
      "value": 655
     }
    },
    "775e000644e440d089293e8b910d178a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "797685b08d3c4ecd8c30d0c79054b3cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_775e000644e440d089293e8b910d178a",
      "placeholder": "​",
      "style": "IPY_MODEL_2bcabf5862994c1490370b885e0f89d9",
      "value": " 100/100 [33:17&lt;00:00, 19.87s/it]"
     }
    },
    "7f68dd4da4ef4123b06719edcb183b06": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "816137123d6045488e9a8fd526d177be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "training routine: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ced23e85c8f4ede87cbcc941ef4f680",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3462537cd22b43e5a2b737ed16707b9f",
      "value": 100
     }
    },
    "8b17c2b18e0b48dc88e3989e93166dea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f68dd4da4ef4123b06719edcb183b06",
      "placeholder": "​",
      "style": "IPY_MODEL_4929c613bf3e4dfa9a83c0bb2d8033bd",
      "value": " 655/656 [33:14&lt;00:00, 39.58it/s, acc=87.5, epoch=99, loss=0.331]"
     }
    },
    "92f39606bbe3431897eaeb6e4ab75383": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2b0a9ccc71541e8995f231e0ee01cc2",
      "placeholder": "​",
      "style": "IPY_MODEL_b930812f259d44259aed1c658a7c5c46",
      "value": " 139/140 [33:17&lt;00:15, 15.26s/it, acc=79.2, epoch=99, loss=0.62]"
     }
    },
    "a423d566060044498a756b6ab637a2ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "split=val:  99%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ade7f0af9a6546ad908c50efbc8c154b",
      "max": 140,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_488235e00da34f35b6fff060cd969c96",
      "value": 139
     }
    },
    "ade7f0af9a6546ad908c50efbc8c154b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b581131842734886981ade3f3105731a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a423d566060044498a756b6ab637a2ff",
       "IPY_MODEL_92f39606bbe3431897eaeb6e4ab75383"
      ],
      "layout": "IPY_MODEL_e036381fd3f94936b86fd24770e90139"
     }
    },
    "b930812f259d44259aed1c658a7c5c46": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2b0a9ccc71541e8995f231e0ee01cc2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e036381fd3f94936b86fd24770e90139": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e15bcc791cf54c73bdacd7a15d030be4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_816137123d6045488e9a8fd526d177be",
       "IPY_MODEL_797685b08d3c4ecd8c30d0c79054b3cd"
      ],
      "layout": "IPY_MODEL_569eef4f1a054e5a8fe569a5eb684b6a"
     }
    },
    "e87214de4511462dbe6bae717bfb1d63": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f45329d59e3f4542a6349c61a4f4e988": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
